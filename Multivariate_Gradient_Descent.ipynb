{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the assignment you have to implement multivariate gradient descent to find the minimas (local and global) of the given function:\n",
        "Note : you can find different minimas by changing your initialisation.  \n",
        "$f(x) = x^4 + x^2y^2 - y^2 + y^4 + 6$"
      ],
      "metadata": {
        "id": "n_ZwYtYkkhMw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGC301Ynkcth"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",

        "def grad_fun(x,y):\n",
        "  gradx = 4 * x**3 + 2 * x * y**2\n",
        " grady = 4 * y**3 + 2 * x**2 * y - 2 * y\n",
        "  return gradx, grady\n",

        "def func(x, y):\n",
        "    return x**4 + x**2 * y**2 - y**2 + y**4 + 6\n",
        
        "def grad_des(a=0.1, lt=1e-6, initial=(1,1), max=1000):\n",
        "  x,y=initial\n",
        "  grad_x,grad_y=grad_fun(x,y)\n",
        "  for i in range(max):\n",
        "    x0=x-a*grad_x\n",
        "    y0=y-a*grad_y\n",
        "  if np.sqrt((x0-x)**2+(y0-y)**2)<lt:\n",
          "  break\n",
        "  x=x0\n",
        "  y=y0\n",
        "  grad_x,grad_y=grad_fun(x,y)\n",
        "  return x,y\n",
        "  a,b=grad_des()\n",
        "  print(a,b)\n",
        "  print(func(a,b))\n"
      ]
    }
  ]
}
